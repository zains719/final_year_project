{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read multiple (x, 1) csv files into a single datframe\n",
    "def merge_csvs(file_names, folder_name):\n",
    "    return [\n",
    "        pd.read_csv(folder_name + file_name + '.csv')\n",
    "        for file_name in file_names\n",
    "    ]\n",
    "\n",
    "#Â construct ILI rates df\n",
    "ili_rates_folder = '../../data/influenza_rates_data/'\n",
    "ili_files = ['weekStarts', 'weekEnds', 'y']\n",
    "ili_df = pd.concat(merge_csvs(ili_files, ili_rates_folder), axis=1)\n",
    "\n",
    "# construct GSQ frequency df\n",
    "gsq_freqs_folder = '../../data/csv_data/google_search_query_data/'\n",
    "gsq_files = ['dates', 'datenums']\n",
    "\n",
    "queries = pd.read_csv(gsq_freqs_folder + 'queries.csv')\n",
    "qf = pd.read_csv(gsq_freqs_folder + 'Q.csv', header=None)\n",
    "qf.columns = queries['Query']\n",
    "\n",
    "gsq_df = pd.concat(merge_csvs(gsq_files, gsq_freqs_folder) + [qf], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe for interpolated daily ILI rates\n",
    "interpolated_data = []\n",
    "\n",
    "# interpolates the ILI rates for all dates between two thursdays for two rows\n",
    "def interpolate_ili_rate(row1, row2):\n",
    "    start1 = int(row1['Week Start'])\n",
    "    end1 = int(row1['Week End'])\n",
    "    thurs1 = start1 + ((end1 - start1) // 2)\n",
    "    ili_rate1 = row1['ILI Rate']\n",
    "\n",
    "    start2 = int(row2['Week Start'])\n",
    "    end2 = int(row2['Week End'])\n",
    "    thurs2 = start2 + ((end2 - start2) // 2)\n",
    "    ili_rate2 = row2['ILI Rate']\n",
    "\n",
    "    for date in range(thurs1, thurs2):\n",
    "        # linear interpolation formual: y = y1 + (((y2 - y1) / (x2 - x1)) * (x - x1))\n",
    "        interpolated_rate = ili_rate1 + (((ili_rate2 - ili_rate1) / 7) * (date - thurs1))\n",
    "        interpolated_data.append({'Date Number': date, 'ILI Rate': interpolated_rate})\n",
    "\n",
    "# inerpolate the dates between the Thursdays of every 2 adjacnet rows (weeks)\n",
    "for i in range(len(ili_df) - 1):\n",
    "    interpolate_ili_rate(ili_df.iloc[i], ili_df.iloc[i + 1])\n",
    "\n",
    "daily_interpolated_ili_df = pd.DataFrame(interpolated_data)\n",
    "daily_interpolated_ili_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a new dataframe for weekly ILI rates with Thursdays\n",
    "weekly_thursdays = []\n",
    "\n",
    "for i in range(len(ili_df)):\n",
    "    row = ili_df.iloc[i]\n",
    "    start = int(row['Week Start'])\n",
    "    end = int(row['Week End'])\n",
    "    thurs = start + ((end - start) // 2)\n",
    "    ili_rate = row['ILI Rate']\n",
    "    weekly_thursdays.append({'Date Number': thurs, 'ILI Rate': ili_rate})\n",
    "\n",
    "weekly_thursdays_df = pd.DataFrame(weekly_thursdays)\n",
    "\n",
    "# Plotting the weekly ILI rates (Thursdays)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(weekly_thursdays_df['Date Number'], weekly_thursdays_df['ILI Rate'], linestyle='-', color='b')\n",
    "plt.title('Weekly ILI Rates (Thursdays)')\n",
    "plt.xlabel('Date Number')\n",
    "plt.ylabel('ILI Rate')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/weekly_ili_rates_thursdays.png')\n",
    "\n",
    "# Plotting the daily ILI rates\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(daily_interpolated_ili_df['Date Number'], daily_interpolated_ili_df['ILI Rate'], linestyle='-', color='r')\n",
    "plt.title('Daily ILI Rates (Interpolated)')\n",
    "plt.xlabel('Date Number')\n",
    "plt.ylabel('ILI Rate')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/daily_ili_rates_interpolated.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters dataframe by date\n",
    "def filter_df(df, start_date_num, end_date_num):\n",
    "    return (\n",
    "        df[(df['Date Number'] >= start_date_num) & (df['Date Number'] <= end_date_num)]\n",
    "    )\n",
    "\n",
    "start_date_num = 731951\n",
    "end_date_num = 738883\n",
    "\n",
    "# filter data frames to contain intersecting data\n",
    "filtered_ili_df = filter_df(daily_interpolated_ili_df, start_date_num, end_date_num)\n",
    "filtered_gsq_df = filter_df(gsq_df, start_date_num, end_date_num)\n",
    "\n",
    "filtered_gsq_df.loc[:, 'Date'] = pd.to_datetime(filtered_gsq_df['Date'], format='%Y%m%d')\n",
    "\n",
    "filtered_ili_df.reset_index(drop=True, inplace=True)\n",
    "filtered_gsq_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "final_df = pd.concat([filtered_gsq_df, filtered_ili_df['ILI Rate']], axis=1)\n",
    "\n",
    "print(final_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with all zeros\n",
    "zero_columns = final_df.columns[2:-1][(final_df.iloc[:, 2:-1] == 0).all()]\n",
    "\n",
    "# Drop the columns with all zeros\n",
    "final_df.drop(columns=zero_columns, inplace=True)\n",
    "\n",
    "# Optionally reset the index if needed\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(final_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_column = 'Date'\n",
    "date_number_column = 'Date Number'\n",
    "ili_rate_column = 'ILI Rate'\n",
    "query_columns = [col for col in final_df.columns if col not in [date_column, date_number_column, ili_rate_column]]\n",
    "\n",
    "final_df['Date'] = pd.to_datetime(final_df['Date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[[date_column] + query_columns]\n",
    "y = final_df[ili_rate_column]\n",
    "\n",
    "train_start_date = '2009-09-01'\n",
    "test_start_date = '2014-09-01'\n",
    "\n",
    "train_indices = (X[date_column] >= train_start_date) & (X[date_column] < test_start_date)\n",
    "X_train = X[train_indices].iloc[:, 1:]\n",
    "\n",
    "zero_cols_train = X_train.columns[(X_train == 0).all()]\n",
    "zero_cols_train_present = set(zero_cols_train).intersection(set(final_df.columns))\n",
    "\n",
    "final_df.drop(columns=zero_cols_train_present, inplace=True)\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(final_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_columns = [col for col in final_df.columns if col not in [date_column, date_number_column, ili_rate_column]]\n",
    "\n",
    "duplicates = {}\n",
    "\n",
    "for query_column in query_columns:\n",
    "    sort_lower_query = ' '.join(sorted(query_column.lower().split()))\n",
    "    if sort_lower_query not in duplicates:\n",
    "        duplicates[sort_lower_query] = []\n",
    "    duplicates[sort_lower_query].append(query_column)\n",
    "\n",
    "non_dup_query_columns = []\n",
    "num_dups_removed = 0\n",
    "\n",
    "for key, same_queries in duplicates.items():\n",
    "    if len(same_queries) > 1:\n",
    "        num_dups_removed += len(same_queries) - 1\n",
    "    non_dup_query_columns.append(same_queries[0])\n",
    "\n",
    "print(len(query_columns))\n",
    "print(num_dups_removed)\n",
    "print(len(non_dup_query_columns))\n",
    "\n",
    "final_df = final_df[[date_column, date_number_column] + non_dup_query_columns + [ili_rate_column]]\n",
    "print(final_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(final_df['Date'], final_df['flu medicine'], linestyle='-', color='b')\n",
    "plt.title('Flu Medicine Query frequencies')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/flu_medicine_query_frequencies.png')\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(final_df['Date'], final_df['flu nhs'], linestyle='-', color='b')\n",
    "plt.title('Flu NHS Query frequencies')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/flu_nhs_query_frequencies.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 14\n",
    "\n",
    "# Weighted average smoothing function\n",
    "def weighted_average(arr):\n",
    "    n = len(arr)\n",
    "    weights = 1 / np.arange(1, n + 1)[::-1]  # Generate weights in a vectorized way\n",
    "    weighted_sum = np.dot(arr, weights)\n",
    "    weight_sum = weights.sum()\n",
    "    return weighted_sum / weight_sum\n",
    "\n",
    "# Apply rolling weighted average to each query column\n",
    "for index, query in enumerate(non_dup_query_columns):\n",
    "    print(index, query)\n",
    "    final_df[query] = final_df[query].rolling(window=window_size, min_periods=1).apply(weighted_average)\n",
    "\n",
    "final_df.to_csv('../../data/smooth_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(final_df['Date'], final_df['flu medicine'], linestyle='-', color='r')\n",
    "plt.title('Smoothed Flu Medicine Query frequencies')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/smoothed_flu_medicine_query_frequencies.png')\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(final_df['Date'], final_df['flu nhs'], linestyle='-', color='r')\n",
    "plt.title('Smoothed Flu NHS Query frequencies')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/smoothed_flu_nhs_query_frequencies.png')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
